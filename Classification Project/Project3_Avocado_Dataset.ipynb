{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import basic library for EDA\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import avocado.csv file\n",
    "df=pd.read_csv('Avocado.csv',parse_dates=['Date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: \n",
    "    1. Year is int datatype and region and type is object data type and other features are flot datatype.\n",
    "    2. Acoording to our Hypothesis or data region and type are category type.\n",
    "    3. During cleansing process data type change and also check about Year and Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "    1. No missing value in any features.\n",
    "    2. 1517 rows with 13 columns in this dataset.\n",
    "    3. 9 features are float data type,1 feature Year is int data type and 2 features object data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type of type and region\n",
    "df['type']=df['type'].astype('category')\n",
    "df['region']=df['region'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check again\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: Cahnge the data type accoding to data of region and type feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics of Numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    1. Min,25%and 50% value of XLarge Bags is 0 and difference between 75% and max very large.\n",
    "    2. Acoording to above 1 statment skewness and oultliers present in XLarge Bags.\n",
    "    3. In Year feature only two years 2015 and 2016 present.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(df.corr(),cmap='rocket',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    1. Light shades are highly correlated .\n",
    "    2. AveragePrice neagtively correlated to all feature exept Year.\n",
    "    3. AveragePrice higly negatively correlated with 4046 and Large Bags.\n",
    "    4. Year and AveragePrice neagtivelt correlated with other feature.\n",
    "    5. Exept Yaer and AveragePrice all feature positive correlated with each other.\n",
    "    6. Most of the columns are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df:\n",
    "    print(i,'\\n',df[i].unique(),'\\n\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From dates we can get mothly ,daily,yearly average counts of AveragePrice,type,region which can help in data analysis\n",
    "df_dates=pd.DataFrame()\n",
    "df_dates['month']=df['Date'].dt.month_name()\n",
    "df_dates['year']=df['Date'].dt.year\n",
    "df_dates['day']=df['Date'].dt.day_name()\n",
    "df_dates['AveragePrice']=df['AveragePrice']\n",
    "df_dates['region']=df['region']\n",
    "df_dates['type']=df['type']\n",
    "df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averageprice during month of an year\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.barplot(x='month',y='AveragePrice',data=df_dates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    1. AveragePrice is not affect by the month.\n",
    "    2. Price is normally approx same in the month mean not any specific month when avocado demand more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "sns.lineplot(x=\"month\", y=\"AveragePrice\", hue='type', data=df_dates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "    1. In this data set only conventional type avocado avilable other type organic avocado not in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average confirmed during day of week \n",
    "sns.barplot(x='day',y='AveragePrice',data=df_dates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averageprice during  of an year \n",
    "sns.barplot(x='year',y='AveragePrice',data=df_dates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation: AveragePrice in 2016 more than 2015 means year by year damand of avocado increse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='region',y='AveragePrice',data=df_dates,kind='bar',aspect=4)\n",
    "plt.xticks(rotation=60)\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Average Price')\n",
    "plt.title('Average Price of Avocado According to Region')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "    1. Region affect the average price of avocado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values based on \"AveragePrice\" (ascending) and \"year\" (descending)\n",
    "df.sort_values([\"AveragePrice\", \"year\"], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding:\n",
    "    1. The year of date column is same as well as  the year columns if comaprison in above output.\n",
    "    2. month and date not affect the price so if drop the date column than no any information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop date columns \n",
    "df.drop(columns=['Date'],inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Price is always important\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.title(\"Distribution Price\")\n",
    "ax = sns.distplot(df[\"AveragePrice\"], color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=\"type\", x=\"AveragePrice\", data=df, palette = 'pink')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Year = df[['Total Volume' ,'AveragePrice']].groupby(df.year).sum()\n",
    "Year.plot(kind='line', fontsize = 14,figsize=(14,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obsrvation: Average price invercly propostional to total volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,18))\n",
    "sns.barplot(x='AveragePrice',y='region',data=df, palette='Blues_d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "sns.scatterplot(x='AveragePrice',y='region',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Year-wise Average Price\n",
    "plt.figure(figsize=(15,4))\n",
    "sns.lineplot(x=\"year\", y=\"AveragePrice\", hue='type', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#Let's see price variance in terms of 4046,4225,4770\n",
    "#data[['4046', '4225', '4770']].groupby(data['AveragePrice']).sum()\n",
    "#data.AveragePrice.nunique()\n",
    "df[['4046', '4225', '4770']].groupby(df['AveragePrice']).sum().plot(kind='line',figsize=(15,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bags = df[['Small Bags', 'Large Bags']].groupby(df.region).sum()\n",
    "Bags.plot(kind='line', fontsize = 14,figsize=(14,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.iloc[:,5:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check skewness distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution plot for all numeric columns including target columns\n",
    "#In for loop we give describe() function to descriminate numeric columns from categorical columns.\n",
    "#Because describe() function give the summary of numeric columns\n",
    "for i in df.iloc[:,0:9]:\n",
    "    sns.distplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets treat the skewness\n",
    "import numpy as np\n",
    "df.skew()\n",
    "for col in df.skew().index:\n",
    "    if col in df.describe().columns:\n",
    "        if df.skew().loc[col]>0.5:\n",
    "            df[col]=np.sqrt(df[col])\n",
    "        if df.skew().loc[col]<-0.5:\n",
    "            df[col]=np.cbrt(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again check skewness\n",
    "df.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.describe().columns:\n",
    "    sns.boxplot(df[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copy\n",
    "df1=df.copy()\n",
    "df2=df.copy()\n",
    "df3=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z=np.abs(zscore(df1.describe()))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding: No any outliers detect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Splitting x and y for AveragePrice\n",
    "df1_x=df.iloc[:,1:]\n",
    "y=df.iloc[:,:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df1_x['type']=le.fit_transform(df1_x['type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: type of avocado conventonal or organic but in this dataset only conventional type of avocado.\n",
    "    2. Average price of avocado depends on type thats not drop type columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_x['region'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re=pd.get_dummies(df1['region']) #Dummies for 'region'\n",
    "df1_x=pd.concat([df1_x,re],axis=1) #Concatenating the dummies with original data\n",
    "df1_x.drop(columns=['region'],inplace=True) #Dropping 'region'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x=ss.fit_transform(df1_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Validation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# ML Algorithms\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model Export\n",
    "import joblib\n",
    "from joblib import dump #from joblib import load > to load .pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "print('x_train.shape: ',x_train.shape,'x_test.shape: ',x_test.shape,'\\ny_train.shape',y_train.shape,'y_test.shape',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating function for Model Training\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "def models(model, x_train, x_test, y_train, y_test,score,rmse):\n",
    "    #Fit the algorithm on the data\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    #Predict training set:\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    score.append(model.score(x_train,y_train))\n",
    "    rmse.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    print('Score:',model.score(x_train,y_train))\n",
    "    print('RMSE:',np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    print('R2 Score:',r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name,score,rmse=[],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg=LinearRegression()\n",
    "mod='Linear Regression'\n",
    "print('Model Report for', mod)\n",
    "models(lreg,x_train,x_test,y_train,y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "parameters={'alpha':[0.01,1,100]}\n",
    "best=GridSearchCV(Ridge(),parameters)\n",
    "best.fit(x_train,y_train)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rr=Ridge(alpha=0.01)\n",
    "mod='Ridge Regression'\n",
    "print('Model Report for', mod)\n",
    "models(rr,x_train,x_test,y_train,y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "parameters={'alpha':[0.001,0.01,1]}\n",
    "best=GridSearchCV(Lasso(),parameters)\n",
    "best.fit(x_train,y_train)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=Lasso(alpha=0.001)\n",
    "mod='Lasso Regression'\n",
    "print('Model Report for', mod)\n",
    "models(lr,x_train,x_test,y_train,y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "enr=ElasticNet(alpha=0.01)\n",
    "mod='Elastic Net'\n",
    "print('Model Report for', mod)\n",
    "models(enr,x_train, x_test, y_train, y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Support Vector Regression\n",
    "from sklearn.svm import SVR\n",
    "parameters={'kernel':['linear','poly','rbf']}\n",
    "best=GridSearchCV(SVR(),parameters)\n",
    "best.fit(x_train,y_train)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr=SVR(kernel='rbf')\n",
    "mod='Support Vector Regression'\n",
    "print('Model Report for', mod)\n",
    "models(svr,x_train, x_test, y_train, y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "parameters={'max_depth':[8,10,12,15],'min_samples_leaf':[100,150]}\n",
    "best=GridSearchCV(DecisionTreeRegressor(),parameters)\n",
    "best.fit(x_train,y_train)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dct=DecisionTreeRegressor(max_depth=10,min_samples_leaf=100)\n",
    "mod='Decision Tree Regression'\n",
    "print('Model Report for', mod)\n",
    "models(dct,x_train, x_test, y_train, y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "parameters={'n_estimators':[200,300,400],'max_depth':[5,6]}\n",
    "best=GridSearchCV(RandomForestRegressor(),parameters)\n",
    "best.fit(x_train,y_train)\n",
    "best.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf=RandomForestRegressor(n_estimators=200,max_depth=6)\n",
    "mod='Random Forest Regression'\n",
    "print('Model Report for', mod)\n",
    "models(rf,x_train, x_test, y_train, y_test,score,rmse)\n",
    "model_name.append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=pd.DataFrame({'Model Name':model_name,'Score':score,'RMSE':rmse})\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "    1. For Linear Regression when output coulmns is AveragePrice Models score findout.\n",
    "    2. For AveragePrice Random Forest Regression give best score and poor performance by DTR.\n",
    "    3. Random Forest Regression gives 81% score for linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export best Model\n",
    "import joblib\n",
    "from joblib import dump\n",
    "joblib.dump(rf,'RFR_Avocado_Dataset.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithm for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting x and y for Region output\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df2['type']=le.fit_transform(df2['type'])\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df2.drop(columns=['region'])\n",
    "y=df2['region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2.region.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "y=le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x=ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=45)\n",
    "print(x_train.shape,x_test.shape,'\\n',y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score,roc_auc_score,plot_confusion_matrix,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC_AUC only handles binary 0,1 values. Using LabelBinarizer to convert y_test and y_pred\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_roc_auc_score(y_test,y_pred):\n",
    "    lb=LabelBinarizer()\n",
    "    y_test_new=lb.fit_transform(y_test)\n",
    "    y_pred_new=lb.fit_transform(y_pred)\n",
    "    return round(roc_auc_score(y_test_new,y_pred_new)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc=SVC()\n",
    "svc_parameters={'kernel':['linear','sigmoid','poly','rbf'],'C':[1,10]}\n",
    "bsvc=GridSearchCV(svc,svc_parameters)\n",
    "bsvc.fit(x_train,y_train)\n",
    "bsvc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(kernel='linear',C=10)\n",
    "svc.fit(x_train,y_train)\n",
    "y_pred=svc.predict(x_test)\n",
    "svc_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('svc_score:',svc_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn=KNeighborsClassifier()\n",
    "neighbors={'n_neighbors':range(1,30)}\n",
    "bknn=GridSearchCV(knn,neighbors)\n",
    "bknn.fit(x_train,y_train)\n",
    "bknn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(x_train,y_train)\n",
    "y_pred=knn.predict(x_test)\n",
    "knn_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('knn_score:',knn_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "criterion = {'criterion':['gini','entropy']}\n",
    "dtc=DecisionTreeClassifier(random_state=42)\n",
    "bdtc=GridSearchCV(dtc,criterion)\n",
    "bdtc.fit(x_train,y_train)\n",
    "bdtc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier(criterion='entropy',random_state=42)\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred=dtc.predict(x_test)\n",
    "dtc_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('dtc_score:',dtc_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators':range(100,200,300)}\n",
    "rf=RandomForestClassifier(random_state=42)\n",
    "brf=GridSearchCV(rf,parameters)\n",
    "brf.fit(x_train,y_train)\n",
    "brf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "rf.fit(x_train,y_train)\n",
    "y_pred=rf.predict(x_test)\n",
    "rf_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('rf_score:',rf_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc=GradientBoostingClassifier(n_estimators=250)\n",
    "gbc.fit(x_train,y_train)\n",
    "y_pred=gbc.predict(x_test)\n",
    "gbc_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('gbc_score:',gbc_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etc=ExtraTreesClassifier(n_estimators=250)\n",
    "etc.fit(x_train,y_train)\n",
    "y_pred=etc.predict(x_test)\n",
    "etc_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('etc_score:',etc_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#AdaBoost Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada=AdaBoostClassifier(n_estimators=100)\n",
    "ada.fit(x_train,y_train)\n",
    "y_pred=ada.predict(x_test)\n",
    "ada_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('ada_score:',ada_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bagging Classifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bc=BaggingClassifier(n_estimators=250)\n",
    "bc.fit(x_train,y_train)\n",
    "y_pred=bc.predict(x_test)\n",
    "bc_score=round(accuracy_score(y_test,y_pred)*100,2)\n",
    "print('bc_score:',bc_score,'%\\nmulticlass_roc_auc_score:',multiclass_roc_auc_score(y_test,y_pred),'%')\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models={\n",
    "    'SVC': svc,\n",
    "    'KNeighborsClassifier': knn,\n",
    "    'DecisionTreeClassifier': dtc,\n",
    "    'RandomForestClassifier': rf,\n",
    "    'GradientBoostingClassifier': gbc,\n",
    "    'ExtraTreesClassifier': etc,\n",
    "    'AdaBoostClassifier': ada,\n",
    "    'BaggingClassifier': bc,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name,ascore,roc=[],[],[]\n",
    "for name in models.keys():\n",
    "    models[name].fit(x_train,y_train)\n",
    "    models_name.append(name)\n",
    "    y_pred=models[name].predict(x_test)\n",
    "    ascore.append(round(accuracy_score(y_test,y_pred)*100,2))\n",
    "    roc.append(multiclass_roc_auc_score(y_test,y_pred))\n",
    "final=pd.DataFrame({'Model':models_name,'Accuracy Score':ascore,'ROC_AUC_Score':roc}).sort_values(by='Accuracy Score',ascending=False)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "    1. For classification when output columns is 'region' different models score findout.\n",
    "    2. For 'region' output best accuracy score achive by ExtraTreesClassifier.\n",
    "    3. ExtraTreesClassifier give 97% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import dump #from joblib import load > to load .pkl file\n",
    "joblib.dump(etc,'ETC_Avocado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
